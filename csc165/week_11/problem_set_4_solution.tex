\documentclass[12pt]{article}
\usepackage[margin=2.5cm]{geometry}
\usepackage{enumerate}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{fancyhdr}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mdframed}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{listings}
\usepackage{xcolor}


\begin{document}
\title{Problem Set 4 Solution}
\author{Hyungmo Gu}
\maketitle

\section*{Question 1}
\begin{enumerate}[a.]
    \item

    \textbf{Statement:} $\forall f,g:\mathbb{N} \to \mathbb{R}^{+}$,
    $b \in \mathbb{R}^{+}$, $(g(n) \in \Theta(f(n))) \land (n_0 \in \mathbb{N},\:
    n \geq n_0 \Rightarrow f(n) \geq b \land g(n) \geq b) \land (b > 1) \Rightarrow
    \log_b(g(n)) \in \Theta(\log_b(f(n)))$

    \bigskip

    \textbf{Statement Expanded:} $\forall f,g:\mathbb{N} \to \mathbb{R}^{+}$,
    $b \in \mathbb{R}^{+}$, $\Bigl(\exists c_1,c_2,n_0 \in \mathbb{R}^{+},\:\forall n \in \mathbb{N},\:
    n \geq n_0 \Rightarrow c_1 \cdot g(n) \leq f(n) \leq c_2 \cdot g(n)\Bigr) \land \Bigl(\exists n_1 \in \mathbb{N},\:
    n \geq n_1 \Rightarrow f(n) \geq b \land g(n) \geq b \Bigr) \land \Bigl( b > 1 \Bigr) \Rightarrow
    \Bigl(\exists d_1,d_2,n_2 \in \mathbb{R}^{+},\:\forall n \in \mathbb{N},\: n \geq n_2
    \Rightarrow d_1 \cdot \log_b(g(n)) \leq \log_b(f(n)) \leq d_2 \cdot \log_b(g(n) \Bigr)$

    \bigskip

    \begin{proof}
        Let $f,g:\mathbb{N} \to \mathbb{R}^{+}$, and $b \in \mathbb{R}^{+}$. Assume
        $c_1 = 1$, $c_2 = b$, and $n_0 = 1$, and $n \in \mathbb{N}$ such that
        $n \geq n_0$ and $c_1 \cdot g(n) \leq f(n) \leq c_2 \cdot g(n)$. Assume $f(n)$
        and $g(n)$ are eventually $\geq b$. Assume $b > 1$. Let $d_1 = 1$, $d_2 = 2$,
        and $n_2 = n_0$. Assume $n \geq n_2$.

        \bigskip

        We need to show $d_1 \cdot \log_b g(n) \leq \log_b f(n) \leq d_2 \cdot \log_b g(n)$.

        \bigskip

        We will do so in two parts. One for $(d_1 \cdot \log_b g(n) \leq \log_b f(n))$ and
        the other for $(\log_b f(n) \leq d_2 \cdot \log_b g(n))$.

        \bigskip

        \textbf{Part 1 ($d_1 \cdot \log_b g(n) \leq \log_b f(n)$):}

        \bigskip

        The assumption tell us

        \begin{align}
            c_1 \cdot g(n) \leq f(n)
        \end{align}

        \bigskip

        Then, it follows from the fact $\forall x,y \in \mathbb{R}^{+}, x \geq y
        \Leftrightarrow \log x \geq \log y$

        \begin{align}
            \log (c_1 \cdot g(n)) &\leq \log (f(n))
        \end{align}

        \bigskip

        Then, using the fact $b > 1$, we can calculate

        \begin{align}
            \frac{\log (c_1 \cdot g(n))}{\log b} &\leq \frac{\log (f(n))}{\log b}\\
            \frac{\log (c_1) + \log (g(n))}{\log b} &\leq \frac{\log (f(n))}{\log b}
        \end{align}

        \bigskip

        Then,

        \begin{align}
            \frac{\log (g(n))}{\log b} &\leq \frac{\log (f(n))}{\log b}
        \end{align}

        by the fact $c_1 = 1$ and $\log c_1 = 0$.

        \bigskip

        Then, since $\frac{\log f(x)}{\log b} = \log_b f(x)$,

        \begin{align}
            \log_b (g(n)) &\leq \log_b (f(n))
        \end{align}

        \bigskip

        Then, because we know $d_1 = 1$, we can conclude

        \begin{align}
            \log_b (g(n)) &\leq d_1 \cdot \log_b (f(n))
        \end{align}


        \bigskip

        \textbf{Part 2 ($\log_b f(n) \leq d_2 \cdot \log_b g(n)$):}

        \bigskip

        The assumption tells us

        \begin{align}
            f(n) &\leq c_2 \cdot g(n)
        \end{align}

        \bigskip

        Then, it follows from the fact $\forall x,y \in \mathbb{R}^{+}, x \geq y
        \Leftrightarrow \log x \geq \log y$

        \begin{align}
            \log (f(n)) &\leq \log (c_2 \cdot g(n))
        \end{align}

        \bigskip

        Then, using the fact $b > 1$, we can calculate

        \begin{align}
            \frac{\log (f(n))}{\log b} &\leq \frac{\log (c_2 \cdot g(n))}{\log b}\\
            \frac{\log (f(n))}{\log b} &\leq \frac{\log (c_2) + \log (g(n))}{\log b}
        \end{align}

        \bigskip

        Then, since $c_2 = b$,

        \begin{align}
            \frac{\log (f(n))}{\log b} &\leq \frac{\log (b) + \log (g(n))}{\log b}
        \end{align}

        \bigskip

        Then, using the fact $g(n)$ is eventually $\geq b$, we can write

        \begin{align}
            \frac{\log (f(n))}{\log b} &\leq \frac{\log (g(n)) + \log (g(n))}{\log b}\\
            \frac{\log (f(n))}{\log b} &\leq \frac{2 \cdot \log (g(n))}{\log b}
        \end{align}

        \bigskip

        Then, since $\frac{\log f(x)}{\log b} = \log_b f(x)$,

        \begin{align}
            \log_b (f(n)) &\leq 2 \cdot \log_b (g(n))
        \end{align}

        \bigskip

        Then, because we know $d_2 = 2$, we can conclude

        \begin{align}
            \log_b (f(n)) &\leq d_2 \cdot \log_b (g(n))
        \end{align}
    \end{proof}

    \textbf{Notes:}

    \begin{itemize}
        \item $\forall x,y \in \mathbb{R}^{+}, x \geq y \Leftrightarrow \log x \geq \log y$


        \item $\exists c_1,c_2,n_0 \in \mathbb{R}^{+},\:\forall n \in \mathbb{N},
        n \geq n_0 \Rightarrow c_1 \cdot g(n) \leq f(n) \leq c2 \cdot g(n)$

        \item \textbf{Definition of Eventually:} $\exists n_0 \in \mathbb{N},
        n \geq n_0 \Rightarrow P$, where $P:\mathbb{N} \to \{\text{True},\text{False}\}$
    \end{itemize}

    \item

    \begin{proof}
        Let $k \in \mathbb{N}$.

        \bigskip

        First, we will analyze the cost of loop 2 over iteration of loop 1.

        \bigskip

        The code tells us loop 2 starts at $j_k = 1$ with $j_k$ increasing by
        a factor of 3 per iteration until $j_k \geq 1$.

        \bigskip

        Using these facts, we can calculate that the terminating condition occurs
        when

        \setcounter{equation}{0}
        \begin{align}
            3^k &\geq i\\
            k &\geq \log_3 i
        \end{align}

        \bigskip

        Because we know the number of iterations is the smallest value of $k$
        satisfying the above inequality, we can conclude loop 2 has

        \begin{align}
            \lceil \log_3 i \rceil
        \end{align}

        iterations.

        \bigskip

        Next, we need to determine the total number of iterations of loop 2
        over all iterations of loop 1.

        \bigskip

        The code tells us loop 1 starts at $i = 1$ and ends at $i = n$ with each
        $i$ increasing by 1 per iteration.

        \bigskip

        Using these facts, we can conclude loop 2 has total of

        \begin{align}
            \lceil \log_3 1 \rceil + \lceil \log_3 2 \rceil + \cdots + \lceil \log_3 n \rceil &= \sum\limits_{i=1}^n \lceil \log_3 i \rceil
        \end{align}

        iterations.
    \end{proof}

    \item
    After scratching head and looking at solution many times, I realized that there
    are many things I do not yet understand, and it's the best to write what I have
    and learn from the solution. Here is my best attempt :).

    \begin{proof}
        Let $n \in \mathbb{N}$.

        \bigskip

        The previous answer tells us the exact cost of the algorithm is
        \setcounter{equation}{0}
        \begin{align}
            \sum\limits_{i=1}^n \lceil \log_3 i \rceil
        \end{align}

        Then, it follows by changing the variable $i$ to $i' = \log_3 i$ we can write

        \begin{align}
            \sum\limits_{i'=0}^{\lceil \log_3 n \rceil} i'
        \end{align}

        \bigskip

        Then, because we know $\sum\limits_{i=0}^n i = \frac{n(n+1)}{2}$, we can
        conclude

        \begin{align}
            \sum\limits_{i'=0}^{\lceil \log_3 n \rceil} i' &= \frac{(\lceil \log_3 n \rceil)(\lceil \log_3 n \rceil + 1)}{2}\\
            &= \frac{\lceil \log_3 n \rceil^2 + \lceil \log_3 n\rceil}{2}
        \end{align}

        \bigskip

        Then, we can conclude the runtime of the algorithm is $\Theta(\log_3^2 n)$.
    \end{proof}

    \bigskip

    \begin{mdframed}
        \underline{\textbf{Correct Solution:}}

        \bigskip

        \color{red}
        We need to determne $\Theta$ of the algorithm.

        \bigskip

        We will prove that the $\Theta$ of the algorithm is $\Theta(n\log n)$.

        \bigskip

        The answer to previous question tells us the total exact cost of the
        algorithm is

        \begin{align}
            \sum\limits_{i=1}^n \lceil \log_3 i \rceil
        \end{align}

        \bigskip

        Then, by using fact 1 $\forall x \in \mathbb{R}, x \leq \lceil x \rceil \leq x + 1$,
        we can calculate

        \begin{align}
            \sum\limits_{i=1}^n \log_3 i &\leq \sum\limits_{i=1}^n \lceil \log_3 i \rceil \leq \sum\limits_{i=1}^n \Bigl( \log_3 i + 1 \Bigr)\\
            \sum\limits_{i=1}^n \log_3 i &\leq \sum\limits_{i=1}^n \lceil \log_3 i \rceil \leq \Bigl(\sum\limits_{i=1}^n \log_3 i + \sum\limits_{i=1}^n 1 \Bigr)\\
            \sum\limits_{i=1}^n \log_3 i &\leq \sum\limits_{i=1}^n \lceil \log_3 i \rceil \leq \sum\limits_{i=1}^n \log_3 i + n
        \end{align}

        \bigskip

        Then,

        \begin{align}
            \log_3 \Bigl(\prod\limits_{i=1}^n i \Bigr) &\leq \sum\limits_{i=1}^n \lceil \log_3 i \rceil \leq \log_3 \Bigl(\prod\limits_{i=1}^n i \Bigr) + n\\
            \log_3 (n!) &\leq \sum\limits_{i=1}^n \lceil \log_3 i \rceil \leq \log_3 (n!) + n
        \end{align}

        by the fact $\forall a,b \in \mathbb{R}^{+}, \log (a) + \log (b) = \log (ab)$.

        \bigskip

        Then,

        \begin{align}
            \frac{\ln n!}{\ln 3} &\leq \sum\limits_{i=1}^n \lceil \log_3 i \rceil \leq \frac{\ln (n!)}{\ln 3} + n
        \end{align}

        by changing the base to $e$ using the formula $\log_3 n! = \frac{\log_e n!}{\log_e 3} = \frac{\ln n!}{\ln 3}$.

        \bigskip

        Now, the fact 2 tells us $n! \in \Theta (e^{n\ln n - n + \frac{1}{2}\ln n})$.

        \bigskip

        Because we know from fact 3 that $n\ln n - n + \frac{1}{2}\ln n$ is
        eventually $\geq 1$, we can conclude $e^{n\ln n - n \frac{1}{2} \ln n}$ is
        eventually $\geq e$.

        \bigskip

        Since $n!$ is also eventually $\geq e$, by using solution to problem 1.a with
        $g(n) = n!$ and $f(n) = e^{n\ln n - n + \frac{1}{2}\ln }$ and $b = e$,
        we can write

        \begin{align}
            \ln(n!) \in \Theta(\ln(e^{n\ln n - n + \frac{1}{2}\ln n}))\\
            \ln(n!) \in \Theta(n\ln n - n + \frac{1}{2}\ln n)
        \end{align}

        \bigskip

        Then,

        \begin{align}
            \ln(n!) \in \Theta(n\ln n)
        \end{align}

        by the fact $n \ln n - n + \frac{1}{2} \ln n \in \Theta(n \ln n)$.

        \bigskip

        So, since the algorithm runs at least $\frac{\ln n!}{\ln 3}$, we can
        conclude it has asymptotic lower bound of $\Omega(n \ln n)$, and since
        the algorithm runs at most $\frac{\ln n!}{\ln 3} + n$, we can conclude it
        has upper bound running time of $\mathcal{O}(n\ln n)$.

        \bigskip

        Since the value of $\Omega$ and $\mathcal{O}$ are the same, we can conclude
        the algorithm has running time of $\Theta(n \ln n)$ or $\Theta(n \log n)$.
        \color{black}

    \end{mdframed}

    \bigskip

    \textbf{Notes:}

    \begin{itemize}
        \item In a main flow of proof, when there is a huge interruption like
        showing $\ln(n!) \in \Theta(n\ln n)$, how can a sentence be started to tell
        the audience we are working on another major idea?

        \item When an interruption in proof has been occured for another
        major part of a proof, how can a sentence be started to combine
        parts together?

        \item How can a sentence be written to say condition $x_1$, $x_2$, and $x_3$
        are satisfied, so a statement $y$ can be used to an equation or an idea?

    \end{itemize}

    \item

    We need to evaluate tight asymptotic upper bound.

    \bigskip

    We will prove that the tight asymptotic upper bound of the algorithm is
    $\mathcal{O}(n^2)$.

    \bigskip

    First, we need to analyze the number of iterations of loop 2 per iteration of
    loop 1.

    \bigskip

    The code tells us loop 2 starts at $j = 0$ and ends at most$j = i - 1$ with
    $j$ increasing by 1 per iteration.

    \bigskip

    Then, using these facts, we can conclude loop 2 has at most

    \setcounter{equation}{0}
    \begin{align}
        \left\lceil \frac{i-1-0+1}{1} \right\rceil = i
    \end{align}

    iterations.

    \bigskip

    Next, we need to determine the total number of iterations of loop 2 over all
    iterations of loop 1.

    \bigskip

    The code tells us that loop 1 starts at $i = n$ and ends at most $i = 0$ with
    $i$ decreasing by 1 per iteration.

    \bigskip

    Because we know each iteration of loop 1 takes $i$ iterations by loop 2, using
    these facts, we can conclude the total number of iterations of loop 2 is at most

    \begin{align}
        n + (n-1) + (n-2) + \cdots + 0 &= \sum\limits_{i=1}^n\\
        &= \frac{n(n+1)}{2}
    \end{align}

    iterations, or $\mathcal{O}(n^2)$.

\end{enumerate}

\section*{Question 2}

\section*{Question 3}

\section*{Question 4}

\end{document}