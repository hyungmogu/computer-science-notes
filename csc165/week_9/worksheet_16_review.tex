\documentclass[12pt]{article}
\usepackage{enumerate}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{fancyhdr}
\usepackage{amssymb}
\usepackage{listings}
\usepackage{mdframed}

\begin{document}
\title{Worksheet 16 Review}
\maketitle

\section*{Question 1}
\begin{enumerate}[a.]
    \item

    Let $k \in \mathbb{N}$.

    \bigskip

    Here, the minimum possible change occurs for the loop variable in a single
    iteration when $i = i + 1$.

    \bigskip

    The maximum possible change occurs for the loop variable in a single
    iteration when $i = i + 6$.

    \bigskip

    The exact upper bound of the variable after k iteration is

    \begin{align}
        i_k &\leq 6k
    \end{align}

    \bigskip

    The exact lower bound of the variable after k iteration is

    \begin{align}
        k &\leq i_k
    \end{align}

    \bigskip

    Using the fact that the termination occurs when $i_k = n$, we can calculate
    that for the upper bound, the loop terminates when

    \begin{align}
        6k &\geq n\\
        k &\geq \frac{n}{6}
    \end{align}

    Because we know $\frac{n}{6}$ may be a decimal, we can conclude the closest value at
    which the loop terminates is when

    \begin{align}
        k &= \left\lceil \frac{n}{6} \right\rceil
    \end{align}

    \bigskip

    Using the same fact, we can calculate that for the lower bound, the loop
    terminates when

    \begin{align}
        k &\geq n
    \end{align}

    It follows from above that for the lower bound, the smallest value of $k$ at which
    the loop termination occurs is when

    \begin{align}
        k &= n
    \end{align}

    \bigskip

    Then, we can conclude the function has asymptotic lower bound of $\Omega(n)$, and
    asymptotic upper bound of $\mathcal{O}(n)$.

    \bigskip

    Then, since both $\Omega$ and $\mathcal{O}$ have the same value, $\Theta(n)$
    is also true.

    \bigskip

    \begin{mdframed}
        \underline{\textbf{Correct Solution:}}

        \bigskip

        Here, the minimum possible change occurs for the loop variable in a single
        iteration when $i = i + 1$.

        \bigskip

        The maximum possible change occurs for the loop variable in a single
        iteration when $i = i + 6$.

        \bigskip

        The exact upper bound of the variable after k iteration is

        \begin{align}
            i_k &\leq 6k
        \end{align}

        \bigskip

        The exact lower bound of the variable after k iteration is

        \begin{align}
            k &\leq i_k
        \end{align}

        \bigskip

        Using the fact that the termination occurs when $i_k = n$, we can calculate
        that for the upper bound, the loop terminates when

        \begin{align}
            6k &\geq n\\
            k &\geq \frac{n}{6}
        \end{align}

        Because we know $\frac{n}{6}$ may be a decimal, we can conclude the closest value at
        which the loop terminates is when

        \begin{align}
            k &= \left\lceil \frac{n}{6} \right\rceil \color{red}+1\color{black}
        \end{align}

        \bigskip

        Using the same fact, we can calculate that for the lower bound, the loop
        terminates when

        \begin{align}
            k &\geq n
        \end{align}

        It follows from above that for the lower bound, the smallest value of $k$ at which
        the loop termination occurs is when

        \begin{align}
            k &= n \color{red}+1\color{black}
        \end{align}

        \bigskip

        Then, we can conclude the function has asymptotic lower bound of $\Omega(n)$, and
        asymptotic upper bound of $\mathcal{O}(n)$.

        \bigskip

        Since both $\Omega$ and $\mathcal{O}$ have the same value, $\Theta(n)$
        is also true.

    \end{mdframed}

    \bigskip

    \textbf{Notes:}

    \begin{itemize}
        \item where is \textbf{+1} coming from? Is it coming from the loop variable $i = 0$?

        % \item Realized \textbf{+ 1} required after thinking there are $n$ iterations
        % between $i = 0$ and $i = n - 1$ when $i = i + 1$.

        % \item Realized \textbf{+ 1} in $\frac{n}{6}$ is required after playing
        % with the following example [0,1,2,3,4,5] and [0,1,2,3,4,5,6].

        % \item Realized $\lceil \frac{5}{6} \rceil = 1$ and $\lceil \frac{6}{6} \rceil = 1$,
        % and indeed \textbf{+ 1} is required to reach loop termination.

        % \item Perhaps the choice of ceiling and floor can be determined by playing with examples.

    \end{itemize}


    \item

    Let $k \in \mathbb{N}$.

    \bigskip

    \textbf{Part 1 (Determining maximum and minimum possible change in a single iteration):}

    \bigskip

    It follows from observation that the minimum possible change occurs when
    $i = i \cdot 2$, and the maximum possible change when $i = i \cdot 3$.

    \bigskip

    \textbf{Part 2 (Determining lower bound and upper bound of loop iteration):}

    \bigskip

    Because we know the smallest possible change occurs when $i = i \cdot 2$
    occurs repeatedly, we can conclude that at $k^{th}$ iteration $i_k$ has
    the lower bound of $2^k$.

    \bigskip

    Similarly, because we know largest possible change occurs when $i = i \cdot 3$
    occurs repeatedly, we can conclude that at $k^{th}$ iteration, $i_k$ has
    the upper bound of $3^k$.

    \bigskip

    Then, by putting together, we can conclude that
    \setcounter{equation}{0}
    \begin{align}
        2^k \leq i_k \leq 3^k
    \end{align}

    \bigskip

    \textbf{Part 3 (Determining exact number of iterations for the lower bound and
    upper bound):}

    \bigskip

    Because we know the loop runs until $i_k < n$, we can conclude that
    at lower bound, termination occurs when

    \begin{align}
        i_k &\geq n\\
        2^k &\geq n\\
        \log_2 2^k &\geq \log_2 n\\
        k &\geq \log_2 n
    \end{align}

    \bigskip

    Using the fact that we are looking for smallest value of $k$, we can calculate that
    for lower bound

    \begin{align}
        k &= \lceil \log_2 n \rceil + 1
    \end{align}

    \bigskip

    Similarly, for the upper bound, loop terminates when

    \begin{align}
        i_k &\geq n\\
        3^k &\geq n\\
        \log_3 3^k &\geq \log_3 n\\
        k &\geq \log_3 n
    \end{align}

    \bigskip

    Using the fact, we can calculate that for upper bound,

    \begin{align}
        k = \lceil \log_3 n \rceil + 1
    \end{align}

    \textbf{Part 4 (Determining Big-Oh and Omega):}

    \bigskip

    Because we know $\log_2 n$ dominates $\log_3 n$, we can conclude
    $\log_2 n$ is the asymptotic upper bound, and $\log_3 n$ is the asymptotic lower bound.

    \bigskip

    Then, we can conclude the algorithm has $\mathcal{O}(\log_2 n)$ and $\Omega(\log_3 n)$.

    \bigskip

    \textbf{Notes:}

    \begin{itemize}
        \item How come in solution, \textbf{+1} doesn't exist? What rules of thumb
        i can follow to better determine whether \textbf{+1} should be included?
    \end{itemize}

\end{enumerate}

\section*{Question 2}
\begin{enumerate}[a.]
    \item

    Because we know $n \in \Theta(n^2)$, we can conclude the algorithm has runtime
    of $\Theta(n^2)$.

    \bigskip

    \begin{mdframed}
        \underline{\textbf{Correct Solution:}}

        \bigskip

        \color{red}
        Since \textbf{helper1} has cost of $n$ and \textbf{helper2} has cost of $n^2$,
        we can conclude the algorithm has total cost of $n + n^2$.

        \bigskip

        It follows from above the algorithm has runtime of $\Theta(n^2)$.

        \color{black}

    \end{mdframed}

    \textbf{Notes:}

    \begin{itemize}
        \item When is $\in$ in $n \in \Theta(n^2)$ used?

        \bigskip

        Is $\in \Theta$ used when $\mathcal{O}$ and $\Omega$ exists with
        different values to choose which value works for both lower and upper
        bound of the algorithm?

        \item Noticed that professor evaluates total runtime before Theta
    \end{itemize}

    \item

    Because we know loop 1 starts at $i = 0$ and finishes at $i = n - 1$ with $i$
    increasing by 2 per iteration, we can conclude loop 1 has

    \setcounter{equation}{0}
    \begin{align}
        \left\lceil \frac{n - 1 - 0 + 1}{2} \right\rceil = \left\lceil \frac{n}{2} \right\rceil
    \end{align}

    iterations.

    \bigskip

    Since each iteration in loop 1 takes $n$ step, as required by \textbf{helper 1} function,
    we can conclude loop 1 has total cost of

    \begin{align}
        n \cdot \left\lceil \frac{n}{2} \right\rceil
    \end{align}

    steps.

    \bigskip

    For loop 2, because we know it starts at $j = 0$ and finishes at $j = 9$,
    we can conclude loop 2 has

    \begin{align}
        \lceil 9 - 0 + 1 \rceil &= 10
    \end{align}

    iterations.

    \bigskip

    Since each iteration in loop 2 takes $n^2$ step as required by \textbf{helper 2} function,
    we can conclude loop 2 has total of

    \begin{align}
        10 \cdot n^2
    \end{align}

    steps.

    \bigskip

    Since $i = 0$ and $j = 0$ have cost of 1 step each, the total cost of algorithm
    is

    \begin{align}
        n \cdot \left\lceil \frac{n}{2} \right\rceil + 10n^2 + 2
    \end{align}

    \bigskip

    Then, we can conclude the algorithm has running time of $\Theta(n^2)$

    \bigskip

    \begin{mdframed}
        \underline{\textbf{Correct Solution:}}

        \bigskip

        Because we know loop 1 starts at $i = 0$ and finishes at $i = n - 1$ with $i$
        increasing by 2 per iteration, we can conclude loop 1 has

        \setcounter{equation}{0}
        \begin{align}
            \left\lceil \frac{n - 1 - 0 + 1}{2} \right\rceil = \left\lceil \frac{n}{2} \right\rceil
        \end{align}

        iterations.

        \bigskip

        Since each iteration in loop 1 takes $n$ step, as required by \textbf{helper 1} function,
        we can conclude loop 1 has total cost of

        \begin{align}
            n \cdot \left\lceil \frac{n}{2} \right\rceil
        \end{align}

        steps.

        \bigskip

        For loop 2, because we know it starts at $j = 0$ and finishes at $j = 9$,
        we can conclude loop 2 has

        \begin{align}
            \lceil 9 - 0 + 1 \rceil &= 10
        \end{align}

        iterations.

        \bigskip

        Since each iteration in loop 2 takes $n^2$ step as required by \textbf{helper 2} function,
        we can conclude loop 2 has total of

        \begin{align}
            10 \cdot n^2
        \end{align}

        steps.

        \bigskip

        \color{red} Combining together \color{black}, the total cost of algorithm
        is

        \begin{align}
            n \cdot \left\lceil \frac{n}{2} \right\rceil + 10n^2
        \end{align}

        \bigskip

        Then, we can conclude the algorithm has running time of $\Theta(n^2)$
        \color{black}

    \end{mdframed}

    \textbf{Notes:}

    \begin{itemize}
        \item Noticed professor doesn't count loop variables toward the total
        cost of algorithm.

        \bigskip

        If other lines such as \textbf{return False} and \textbf{n = len(lst)} are
        included, would these count towards the total cost of the algorithm?

    \end{itemize}

    \item

    For loop 1, because we know it starts at $i = 0$ and finishes at $i = n - 1$ with each
    iteration having cost of i steps, we can conclude loop 1 has cost of

    \setcounter{equation}{0}
    \begin{align}
        \sum\limits_{i=0}^{n-1} i = \frac{n(n-1)}{2}
    \end{align}

    steps.

    \bigskip

    For loop 2, because we know it starts at $j = 0$ and finishes at $j = 9$ with
    each iteration costing $j^2$ steps, we can conclude loop 2 has

    \begin{align}
        \sum\limits_{j=0}^{9} j^2 &= \frac{9(9-1)(2(9)-1)}{6}\\
        &= \frac{9 \cdot 8 \cdot 17}{6}\\
        &= 204
    \end{align}

    steps.

    \bigskip

    Combining together, the total cost of algorithm is

    \begin{align}
        \frac{n(n-1)}{2} + 204
    \end{align}

    steps.

    \bigskip

    Then, we can conclude the running time of algorithm is $\Theta(n^2)$.



\end{enumerate}

\section*{Question 3}
\begin{enumerate}[a.]
    \item

    \textbf{Predicate Logic:} $\forall x \in \mathbb{Z}^{+}$, $k \in \mathbb{N}$,
    (three iterations occur) $\Rightarrow x_{3(k+1)} \leq \displaystyle\frac{x_{3k}}{2}$

    \bigskip

    \begin{proof}

        Let $k \in \mathbb{N}$.

        \bigskip

        Assume three iterations occur in loop.

        \bigskip

        We will show $x_{3(k+1)} \leq \displaystyle\frac{x_{3k}}{2}$ using proof by cases.

        \bigskip

        \textbf{Case 1 ($x$ divisible by 2 three times):}

        \bigskip

        Assume $x$ is divisible by 2 at least 3 times.

        \bigskip

        Because we know the if condition $x\:\mod\:2 == 0$ is true in all iterations,
        we can conclude the line \textbf{x = x // 2} will run 3 times.

        \bigskip

        Then, it follows from above that the value of $x$ at $3(k+1)^{th}$ iteration
        is

        \begin{align}
            x_{3(k+1)} &= \frac{x_{3k}}{2^3}
        \end{align}

        \bigskip

        Then, because we know $\frac{1}{2^3} \leq \frac{1}{2}$, we can conclude

        \begin{align}
            x_{3(k+1)} &\leq \frac{1}{2} x_{3k}
        \end{align}

        \bigskip

        \textbf{Case 2 ($x$ divisible by 2 two times):}

        \bigskip

        Assume $x$ is divisible by 2, 2 times.

        \bigskip

        Because we know the if condition \textbf{$x \mod 2$ == 0} is true in first two
        iterations, we can conclude the line \textbf{x = x // 2} will run twice.

        \bigskip

        Then, at the end of second iteration, we can conclude $x$ will have the value of

        \begin{align}
            \frac{x_{3k}}{2^2}
        \end{align}

        \bigskip

        On the final iteration, because we know the if condition \textbf{$x \mod 2$ == 0}
        is false, we can conclude the line \textbf{x = 2 * x - 2} will run.

        \bigskip

        Then, using the above fact, we can calculate

        \begin{align}
            x_{3(k+1)} &= \frac{x_{3k}}{2^2} \cdot 2 - 2\\
            &= \frac{x_{3k}}{2} - 2\\
            &\leq \frac{x_{3k}}{2}
        \end{align}

        \bigskip

        \textbf{Case 3 ($x$ divisible by 2 once):}

        \bigskip

        Assume $x$ is divisible by 2 once.

        \bigskip

        Because we know the if condition \textbf{$x \mod 2$ == 0} is true in first iteration,
        we can conclude the line \textbf{x = x // 2} will run.

        \bigskip

        Then, at the end of first iteration, we can conclude $x$ will have the value
        of

        \begin{align}
            \frac{x_{3k}}{2}
        \end{align}

        \bigskip

        On the second iteration, because we know \textbf{$x \mod 2$ == 0} is false,
        we can conclude the line \textbf{x = 2 * x - 2} will run.

        \bigskip

        Then, at the ned of second iteration, we can conclude $x$ will have the
        value of

        \begin{align}
            \frac{x_{3k}}{2} \cdot 2 - 2 = 3_{3k} - 2
        \end{align}

        \bigskip

        On the final iteration, because we know from assumption $2 \mid x_{3k}$ and $2 \mid -2$,
        we can conclude the if condition \textbf{$x \mod 2$ == 0} will be satisfied
        and the line \textbf{x = x // 2} will run.

        \bigskip

        Then, at the end of final iteration, we can conclude $x_{3(k+1)}$ will
        have the value of

        \begin{align}
            x_{3(k+1)} &= \frac{x_{3k} - 2}{2}\\
            &\leq \frac{x_{3k}}{2}
        \end{align}

        \bigskip

        \textbf{Case 4 ($x$ is an odd number):}

        \bigskip

        Assume $x$ is an odd number.

        \bigskip

        Because we know \textbf{$x \mod 2$ == 0} is false in first iteration,
        we can conclude the line \textbf{x = 2 * x - 2} will run.

        \bigskip

        Then, at the end of first iteration, we can conclude $x$ will have the
        value of

        \begin{align}
            x_{3k} \cdot 2 - 2 &= 2 \cdot (x_{3k} - 1)
        \end{align}

        \bigskip

        On the second iteration, because we know the if condition \textbf{$x \mod 2$ == 0}
        is true, we can conclude the line \textbf{x = x // 2} will run.

        \bigskip

        Then, at the end of second iteration, we can conclude $x$ will have the
        value of

        \begin{align}
            \frac{2 \cdot (x_{3k} - 1)}{2} &= x_{3k} - 1
        \end{align}

        \bigskip

        On the final iteration, because we know $x_{3k} - 1$ is an even number,
        we can conclude the if condition \textbf{$x \mod 2$ == 0} is true, and
        the line \textbf{x = x // 2} will run.

        \bigskip

        Then, at the end of final iteration, we can conclude $x_{3(k+1)}$ will
        have the value of

        \begin{align}
            x_{3(k+1)} &= \frac{x_{3k} - 1}{2}\\
            &\leq \frac{x_{3k}}{2}
        \end{align}

    \end{proof}

    \item

    Let $k \in \mathbb{N}$.

    \bigskip

    We need to find the smallest value of $k$ in terms of $n$ at which the loop
    termination occurs.

    \bigskip

    The result in previous problem tells us that every 3 iterations, $x$ decreases
    by half. So, initially we have

    \setcounter{equation}{0}
    \begin{align}
        x_3 &\leq \frac{x_0}{2}
    \end{align}

    \bigskip

    Then, we can conclude that at $3k$ iterations,

    \begin{align}
        x_3 &\leq \frac{x_0}{2^k}
    \end{align}

    \bigskip

    Then, since $x_0 = n$,

    \begin{align}
        x_3 &\leq \frac{n}{2^k}
    \end{align}

    \bigskip

    Using the fact that the loop termination occurs when $x \leq 1$, we can
    calculate

    \begin{align}
        2^k &\geq n\\
        k &\geq \log n
    \end{align}

    \bigskip

    Then, it follows from above the smallest value of $k$ at which termination occurs
    is

    \begin{align}
        \lceil \log n \rceil
    \end{align}

    \bigskip

    Then, we can conclude the running time of algorithm is $\Theta (\log n)$


\end{enumerate}


\end{document}